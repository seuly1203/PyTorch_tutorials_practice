{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyG_creating-own-datasets.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "62WQOBHznFQo"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# install"
      ],
      "metadata": {
        "id": "62WQOBHznFQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhQXYuZBm8zt",
        "outputId": "af194cda-62f1-41f5-aa87-3f46d2df88a9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.0.4.tar.gz (407 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 33.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 51 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 61 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 71 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 81 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 92 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 102 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 112 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 122 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 133 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 143 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 153 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 163 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 174 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 184 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 194 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 204 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 215 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 225 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 235 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 245 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 256 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 266 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 276 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 286 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 296 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 307 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 317 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 327 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 337 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 348 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 358 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 368 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 378 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 389 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 399 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 407 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (4.63.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (3.0.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch_geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch_geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch_geometric) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2021.10.8)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.4-py3-none-any.whl size=616603 sha256=791316e2cc4f3c3923aa29fc800b7e87bc6a4f4030004b2a9c12343e0419e282\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/a6/a4/ca18c3051fcead866fe7b85700ee2240d883562a1bc70ce421\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch_sparse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmg5WwwOnAaS",
        "outputId": "2290a683-ef3a-4107-b70e-51874cf7652d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_sparse\n",
            "  Downloading torch_sparse-0.6.13.tar.gz (48 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▊                         | 10 kB 39.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 20 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 30 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 40 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 48 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch_sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch_sparse) (1.21.5)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.13-cp37-cp37m-linux_x86_64.whl size=1669162 sha256=36dee5e4709e752a0796bfcb6bfb17c187480843acb2ca7a93b1af36d6e64e6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/01/be/6b2966e0ff20bb023ae35e5d17903e6e5b4df46dd5892f6be6\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch_scatter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPY47WnhnBv6",
        "outputId": "aafda75b-c459-4019-c937-8958ea18772f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_scatter\n",
            "  Downloading torch_scatter-2.0.9.tar.gz (21 kB)\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl size=3874186 sha256=7df852bb525b06a4a0e9bbd2cd1e690b24fff0bc12c0fa11d7b592357d4d11ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/57/a3/42ea193b77378ce634eb9454c9bc1e3163f3b482a35cdee4d1\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Own Datasets \n",
        "\n",
        "abstract classes for datasets:\n",
        "- torch_geometric.data.Dataset\n",
        "- torch_geometric.data.InMemoryDataset\n",
        "  - [InMemoryDataset] inherits from [Dataset] and should be used if the whole dataset fits into CPU memory\n",
        "\n",
        "\n",
        "- torchvision 처럼 각각의 dataset은 'root folder'(dataset 저장되는 폴더)를 받는데 PyG에서는 이걸 'raw_dir' 폴더와 'processed_dir' 폴더로 나눔\n",
        "  - raw_dir: 데이터셋 다운로드 하는 경로\n",
        "  - processed_dir: 처리된 데이터셋이 저장되는 경로\n",
        "\n",
        "- 각각의 dataset은 'tranfrom', 'pre_transform', 'pre_filter' 함수를 인자로 받을 수 있는데 모두 default는 None\n",
        "  - tranform: transforms the data object before accessing to make it best used for data augmentation.\n",
        "  - pre_transform: applies the transformation before saving the data objects to disk - so it is best used for heavy precomputation which needs to be only done once.\n",
        "  - pre_filter: filters out data objects before saving"
      ],
      "metadata": {
        "id": "JVcnspUhcxlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating \"In Memory Datasets\"\n",
        "\n",
        "FOUR fundmental methods for creating a 'pyg.data.InMemoryDataset'\n",
        " 1. torch_geometric.data.InMemoryDataset.raw_file_names()\n",
        "  : raw_dir에 있는 파일 리스트\n",
        " 2. torch_geometric.data.InMemoryDataset.processed_file_names()\n",
        "  : processed_dir에 있는 파일 리스트\n",
        " 3. torch_geometric.data.InMemoryDataset.download()\n",
        "  : raw data를 raw_dir에 다운로드\n",
        " 4. torch_geometric.data.InMemoryDataset.process()\n",
        "  : raw data를 process하여 processed_dir에 저장"
      ],
      "metadata": {
        "id": "oxes6nAldfzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import InMemoryDataset, download_url\n",
        "\n",
        "class MyOwnDataset(InMemoryDataset):\n",
        "  def __init__(self, root, transform=None, pre_transform=None, \n",
        "               pre_filter=None):\n",
        "    super().__init__(root, transform, pre_transform, pre_filter)\n",
        "    self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "  @property\n",
        "  def raw_file_names(self):\n",
        "    return ['some_file_1', 'some_file_2', ...]\n",
        "  \n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    return ['data.pt']\n",
        "\n",
        "  def download(self):\n",
        "    # download to 'self.raw_dir'.\n",
        "    download_url(url, self.raw_dir)\n",
        "    ...\n",
        "\n",
        "  def process(self):\n",
        "    # read data into huge 'Data' list.\n",
        "    data_list = [...] # a list of Data objects\n",
        "\n",
        "    if self.pre_filter is not None:\n",
        "      data_list = [data for data in data_list if self.pre_filter(data)]\n",
        "\n",
        "    if self.pre_transform is not None:\n",
        "      data_list = [self.pre_transform(data) for data in data_list]\n",
        "\n",
        "    data, slices = self.collate(data_list) #  Collating the list into one huge Data object via .collate() - a huge python list 저장하는 거 느리기때문\n",
        "    # The collated data object has concatenated all examples into one big data object\n",
        "    # + returns a slices dictionary to reconstruct single examples from this object.\n",
        "\n",
        "    torch.save((data, slices), self.processed_paths[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "HDhM7KAgfjo8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating \"Larger\" Datasets\n",
        "\n",
        "- torch_geometric.data.Dataset\n",
        "  - can be used for creating datasets which do not fit into memory\n",
        "  - it closely follows the concepts of the torchvision datasets. \n",
        "  - It expects the following methods to be implemented in addition:\n",
        "    - torch_geometric.data.Dataset.len(): Returns the number of examples in your dataset.\n",
        "    - torch_geometric.data.Dataset.get(): Implements the logic to load a single graph.\n",
        "\n",
        "- torch_geometric.data.Dataset. _ _ getitem _ _() \n",
        "  - gets data objects from torch_geometric.data.Dataset.get() and optionally transforms them according to transform.\n",
        "\n",
        "Let’s see this process in a simplified example:"
      ],
      "metadata": {
        "id": "DwD-O7AHdjTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "from torch_geometric.data import Dataset, download_url\n",
        "\n",
        "\n",
        "class MyOwnDataset(Dataset):\n",
        "  def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
        "    super().__init__(root, transform, pre_transform, pre_filter)\n",
        "\n",
        "  @property\n",
        "  def raw_file_names(self):\n",
        "    return ['some_file_1', 'some_file_2', ...]\n",
        "\n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    return ['data_1.pt', 'data_2.pt', ...]\n",
        "\n",
        "  def download(self):\n",
        "    # Download to `self.raw_dir`.\n",
        "    path = download_url(url, self.raw_dir)\n",
        "    ...\n",
        "\n",
        "  def process(self):\n",
        "    idx = 0\n",
        "    for raw_path in self.raw_paths:\n",
        "      # Read data from `raw_path`.\n",
        "      data = Data(...)\n",
        "\n",
        "      if self.pre_filter is not None and not self.pre_filter(data):\n",
        "        continue\n",
        "\n",
        "      if self.pre_transform is not None:\n",
        "        data = self.pre_transform(data)\n",
        "\n",
        "      torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
        "      idx += 1\n",
        "\n",
        "  def len(self):\n",
        "    return len(self.processed_file_names)\n",
        "\n",
        "  def get(self, idx):\n",
        "    data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
        "    return data\n",
        "\n",
        "# Here, each graph data object gets saved individually in process(), and is manually loaded in get()."
      ],
      "metadata": {
        "id": "4XbIOe9YrY-Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises"
      ],
      "metadata": {
        "id": "ORylsTAddofs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider the following InMemoryDataset constructed from a list of Data objects:"
      ],
      "metadata": {
        "id": "4v8zelL4uIfm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lVNCwZw7bNld"
      },
      "outputs": [],
      "source": [
        "class MyDataset(InMemoryDataset):\n",
        "  def __init__(self, root, data_list, transform=None):\n",
        "    self.data_list = data_list\n",
        "    super.__init__(root, transform)\n",
        "    self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    return 'data.pt'\n",
        "  \n",
        "  def process(self):\n",
        "    torch.save(self.collate(self.data_list), self.processed_paths[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is the output of self.processed_paths[0]?\n",
        "2. What does collate() do?"
      ],
      "metadata": {
        "id": "JVNSEciVuNlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Beginner’s Guide to Graph Neural Networks Using PyTorch Geometric — Part 1 by R. Teja (일부)\n",
        "\n",
        "출처: https://towardsdatascience.com/a-beginners-guide-to-graph-neural-networks-using-pytorch-geometric-part-1-d98dc93e7742"
      ],
      "metadata": {
        "id": "ZCIOH63CzfVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset: Zachary's Karate Club\n",
        "# 34 nodes (students in the club)\n",
        "# 78 edges (interactions between pairs of members outside the club)\n",
        "# 2 labels (2 factions)"
      ],
      "metadata": {
        "id": "5oh3st7D0koS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### preparations"
      ],
      "metadata": {
        "id": "vfXWQo8P20rW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# load graph from networkx library\n",
        "G = nx.karate_club_graph()\n",
        "\n",
        "# retrieve the labels for each node\n",
        "labels = np.asarray([G.nodes[i]['club'] != 'Mr. Hi' for i in G.nodes]).astype(np.int64)\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRHiixo7044u",
        "outputId": "2a1f1c19-127c-4460-9110-cf7201411116"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'G.nodes: {G.nodes}')\n",
        "print(f'G.nodes[1]: {G.nodes[1]}')\n",
        "print(f'G.nodes[31]: {G.nodes[33]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBTRmQbn1_mv",
        "outputId": "a9cee4ce-9b84-40e8-e884-b788e9e59d80"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G.nodes: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]\n",
            "G.nodes[1]: {'club': 'Mr. Hi'}\n",
            "G.nodes[31]: {'club': 'Officer'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adj = nx.to_scipy_sparse_matrix(G)\n",
        "adj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hrIT4Fe3k0n",
        "outputId": "682b3814-d769-4e0d-a982-fd4a1d70a0ec"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<34x34 sparse matrix of type '<class 'numpy.longlong'>'\n",
              "\twith 156 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create edge index from\n",
        "adj = nx.to_scipy_sparse_matrix(G).tocoo()\n",
        "row = torch.from_numpy(adj.row.astype(np.int64)).to(torch.long)\n",
        "col = torch.from_numpy(adj.col.astype(np.int64)).to(torch.long)\n",
        "edge_index = torch.stack([row, col], dim=0)\n",
        "\n",
        "print(f'adj:{adj}\\n\\nrow:{row}\\n\\ncol:{col}\\n\\nedge_index:{edge_index}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oECefjuA2xYl",
        "outputId": "4aaf4bd0-bfbb-4bf9-d835-9ecdeef7a803"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adj:  (0, 1)\t1\n",
            "  (0, 2)\t1\n",
            "  (0, 3)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 5)\t1\n",
            "  (0, 6)\t1\n",
            "  (0, 7)\t1\n",
            "  (0, 8)\t1\n",
            "  (0, 10)\t1\n",
            "  (0, 11)\t1\n",
            "  (0, 12)\t1\n",
            "  (0, 13)\t1\n",
            "  (0, 17)\t1\n",
            "  (0, 19)\t1\n",
            "  (0, 21)\t1\n",
            "  (0, 31)\t1\n",
            "  (1, 0)\t1\n",
            "  (1, 2)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 7)\t1\n",
            "  (1, 13)\t1\n",
            "  (1, 17)\t1\n",
            "  (1, 19)\t1\n",
            "  (1, 21)\t1\n",
            "  (1, 30)\t1\n",
            "  :\t:\n",
            "  (32, 18)\t1\n",
            "  (32, 20)\t1\n",
            "  (32, 22)\t1\n",
            "  (32, 23)\t1\n",
            "  (32, 29)\t1\n",
            "  (32, 30)\t1\n",
            "  (32, 31)\t1\n",
            "  (32, 33)\t1\n",
            "  (33, 8)\t1\n",
            "  (33, 9)\t1\n",
            "  (33, 13)\t1\n",
            "  (33, 14)\t1\n",
            "  (33, 15)\t1\n",
            "  (33, 18)\t1\n",
            "  (33, 19)\t1\n",
            "  (33, 20)\t1\n",
            "  (33, 22)\t1\n",
            "  (33, 23)\t1\n",
            "  (33, 26)\t1\n",
            "  (33, 27)\t1\n",
            "  (33, 28)\t1\n",
            "  (33, 29)\t1\n",
            "  (33, 30)\t1\n",
            "  (33, 31)\t1\n",
            "  (33, 32)\t1\n",
            "\n",
            "row:tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,\n",
            "         1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,\n",
            "         3,  3,  3,  3,  3,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,\n",
            "         7,  7,  8,  8,  8,  8,  8,  9,  9, 10, 10, 10, 11, 12, 12, 13, 13, 13,\n",
            "        13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 19, 20, 20, 21,\n",
            "        21, 22, 22, 23, 23, 23, 23, 23, 24, 24, 24, 25, 25, 25, 26, 26, 27, 27,\n",
            "        27, 27, 28, 28, 28, 29, 29, 29, 29, 30, 30, 30, 30, 31, 31, 31, 31, 31,\n",
            "        31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33,\n",
            "        33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33])\n",
            "\n",
            "col:tensor([ 1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 17, 19, 21, 31,  0,  2,\n",
            "         3,  7, 13, 17, 19, 21, 30,  0,  1,  3,  7,  8,  9, 13, 27, 28, 32,  0,\n",
            "         1,  2,  7, 12, 13,  0,  6, 10,  0,  6, 10, 16,  0,  4,  5, 16,  0,  1,\n",
            "         2,  3,  0,  2, 30, 32, 33,  2, 33,  0,  4,  5,  0,  0,  3,  0,  1,  2,\n",
            "         3, 33, 32, 33, 32, 33,  5,  6,  0,  1, 32, 33,  0,  1, 33, 32, 33,  0,\n",
            "         1, 32, 33, 25, 27, 29, 32, 33, 25, 27, 31, 23, 24, 31, 29, 33,  2, 23,\n",
            "        24, 33,  2, 31, 33, 23, 26, 32, 33,  1,  8, 32, 33,  0, 24, 25, 28, 32,\n",
            "        33,  2,  8, 14, 15, 18, 20, 22, 23, 29, 30, 31, 33,  8,  9, 13, 14, 15,\n",
            "        18, 19, 20, 22, 23, 26, 27, 28, 29, 30, 31, 32])\n",
            "\n",
            "edge_index:tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,\n",
            "          3,  3,  3,  3,  3,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,\n",
            "          7,  7,  8,  8,  8,  8,  8,  9,  9, 10, 10, 10, 11, 12, 12, 13, 13, 13,\n",
            "         13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 19, 20, 20, 21,\n",
            "         21, 22, 22, 23, 23, 23, 23, 23, 24, 24, 24, 25, 25, 25, 26, 26, 27, 27,\n",
            "         27, 27, 28, 28, 28, 29, 29, 29, 29, 30, 30, 30, 30, 31, 31, 31, 31, 31,\n",
            "         31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33,\n",
            "         33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33],\n",
            "        [ 1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 17, 19, 21, 31,  0,  2,\n",
            "          3,  7, 13, 17, 19, 21, 30,  0,  1,  3,  7,  8,  9, 13, 27, 28, 32,  0,\n",
            "          1,  2,  7, 12, 13,  0,  6, 10,  0,  6, 10, 16,  0,  4,  5, 16,  0,  1,\n",
            "          2,  3,  0,  2, 30, 32, 33,  2, 33,  0,  4,  5,  0,  0,  3,  0,  1,  2,\n",
            "          3, 33, 32, 33, 32, 33,  5,  6,  0,  1, 32, 33,  0,  1, 33, 32, 33,  0,\n",
            "          1, 32, 33, 25, 27, 29, 32, 33, 25, 27, 31, 23, 24, 31, 29, 33,  2, 23,\n",
            "         24, 33,  2, 31, 33, 23, 26, 32, 33,  1,  8, 32, 33,  0, 24, 25, 28, 32,\n",
            "         33,  2,  8, 14, 15, 18, 20, 22, 23, 29, 30, 31, 33,  8,  9, 13, 14, 15,\n",
            "         18, 19, 20, 22, 23, 26, 27, 28, 29, 30, 31, 32]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using degreee as embedding\n",
        "embeddings = np.array(list(dict(G.degree()).values()))\n",
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RodqO1D4A4R",
        "outputId": "9d505ccf-807e-444e-aab4-0d320e4310a2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([16,  9, 10,  6,  3,  4,  4,  4,  5,  2,  3,  1,  2,  5,  2,  2,  2,\n",
              "        2,  2,  3,  2,  2,  2,  5,  3,  3,  2,  4,  3,  4,  4,  6, 12, 17])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizing degree values\n",
        "scale = StandardScaler()\n",
        "embeddings = scale.fit_transform(embeddings.reshape(-1, 1))\n",
        "print(f'scaled embeddings:\\n{embeddings}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWblUXCZ4nGp",
        "outputId": "1d83851e-69ba-4c06-f2e6-08e0fcabc9a5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scaled embeddings:\n",
            "[[ 2.98709092]\n",
            " [ 1.15480319]\n",
            " [ 1.41655858]\n",
            " [ 0.36953702]\n",
            " [-0.41572915]\n",
            " [-0.15397376]\n",
            " [-0.15397376]\n",
            " [-0.15397376]\n",
            " [ 0.10778163]\n",
            " [-0.67748454]\n",
            " [-0.41572915]\n",
            " [-0.93923993]\n",
            " [-0.67748454]\n",
            " [ 0.10778163]\n",
            " [-0.67748454]\n",
            " [-0.67748454]\n",
            " [-0.67748454]\n",
            " [-0.67748454]\n",
            " [-0.67748454]\n",
            " [-0.41572915]\n",
            " [-0.67748454]\n",
            " [-0.67748454]\n",
            " [-0.67748454]\n",
            " [ 0.10778163]\n",
            " [-0.41572915]\n",
            " [-0.41572915]\n",
            " [-0.67748454]\n",
            " [-0.15397376]\n",
            " [-0.41572915]\n",
            " [-0.15397376]\n",
            " [-0.15397376]\n",
            " [ 0.36953702]\n",
            " [ 1.94006936]\n",
            " [ 3.24884631]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Custom Dataset"
      ],
      "metadata": {
        "id": "eI_7qPrc3Lzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G.number_of_nodes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8MtXqA6-GXr",
        "outputId": "cf47c6ee-fd0d-4ca9-fada-d41f06be8e1c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch_geometric.data import InMemoryDataset, Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "# custom dataset\n",
        "class KarateDataset(InMemoryDataset):\n",
        "  def __init__(self, transform=None):\n",
        "    super(KarateDataset, self).__init__('.', transform, None, None) # root('.' 현재 디렉토리??), transform, pre_transform, pre_filter\n",
        "\n",
        "    data = Data(edge_index = edge_index) # edge_index 위에서 정의\n",
        "    data.num_nodes = G.number_of_nodes()\n",
        "\n",
        "    # embedding\n",
        "    data.x = torch.from_numpy(embeddings).type(torch.float32) # embeddings 위에서 정의\n",
        "\n",
        "    # labels\n",
        "    y = torch.from_numpy(labels).type(torch.long) # labels 위에서 정의\n",
        "    data.y = y.clone().detach()\n",
        "\n",
        "    data.num_classes = 2\n",
        "\n",
        "    # splitting the data into train, validation and test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(pd.Series(list(G.nodes())),\n",
        "                                                        pd.Series(labels),\n",
        "                                                        test_size = 0.30,\n",
        "                                                        random_state = 42)\n",
        "    n_nodes = G.number_of_nodes()\n",
        "\n",
        "    # create train and test masks for data\n",
        "    train_mask = torch.zeros(n_nodes, dtype = torch.bool)\n",
        "    test_mask = torch.zeros(n_nodes, dtype = torch.bool)\n",
        "    train_mask[X_train.index] = True\n",
        "    test_mask[X_test.index] = True\n",
        "    data['train_mask'] = train_mask\n",
        "    data['test_mask'] = test_mask\n",
        "\n",
        "    self.data, self.slices = self.collate([data])\n",
        "\n",
        "  def _download(self):\n",
        "    return\n",
        "\n",
        "  def _process(self):\n",
        "    return\n",
        "  \n",
        "  def __repr__(self):\n",
        "    return '{}()'.format(self.__class__.name__)\n",
        "\n",
        "\n",
        "dataset = KarateDataset()\n",
        "data = dataset[0]"
      ],
      "metadata": {
        "id": "bn_dxpuYzkD4"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAAEBazL9La9",
        "outputId": "8a1b4538-dd88-4264-825d-16cbb7cb5a69"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(edge_index=[2, 156], num_nodes=34, x=[34, 1], y=[34], num_classes=2, train_mask=[34], test_mask=[34])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    }
  ]
}